<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./styles/inicio.css" type="text/css">
    <link rel="stylesheet" href="./styles/ayuda.css" type="text/css">
    <link rel="stylesheet" href="./styles/pie.css" type="text/css">


    <title>Imágenes generadas por IA</title>
</head>
<body>

    <div class="navegador">
        <div class="ayuda_setc1">
            <h1 class="sect1">Las imágenes generadas por Inteligencia Artificial son cada vez más realistas</h1>
            <p>
                Las posibilidades que nos ofrece la Inteligencia Artificial hoy en día
                eran inimaginables hace unos años. Con el avance de la tecnología también
                han surgido nuevas formas de estafa, acoso y extorsión, facilitando la vida
                a gente que busca aprovecharse de la situación ignorando la ética y el derecho digital de la autonomía
                y libertad de pensamiento. <a href="https://es.wikipedia.org/wiki/Fake_news">Fake news</a>, bulos, imágenes falsas, vídeos manipulados (deepfakes)... La
                desinformación es un problema muy importante actualmente. Todas estas nuevas formas de engaño,
                a través de las redes y el mundo conectado en el que vivimos, se transmiten a una velocidad alarmante.
                <strong>
                    <br><br>
                    Aquí nos hemos centrado en la generación de imágenes de personas que no existen y hemos puesto
                    un par de ejemplos de cómo con gatos, también ocurre (al igual que con más objetos...sí, no sólo
                    genera rostros). Por ello os hemos propuesto el test de imágenes para que vosotros mismos comprobéis
                    lo difícil que es distinguir, en el caso de personas, una persona real de una hecha por IA. Algunas
                    de las fotos reales han sido obtenidas de la colección <a href="https://github.com/NVlabs/ffhq-dataset">FFHQ </a>
                    y las fotos no reales de <a href="https://thispersondoesnotexist.com/">“this person does not exist” </a>
                    y <a href="https://thiscatdoesnotexist.com/">“this cat does not exist”</a> (hay varias páginas del estilo).
                    En el caso de la generación de objetos u otros animales, destacamos por ejemplo
                    a <a href="https://junyanz.github.io/CycleGAN/">CycleGAN</a>.<br>
                </strong>
                <br>
                Se utiliza una tecnología basada en redes neuronales, las GAN (Generative Adversary Networks), que en español
                significa “Redes generativas adversarias”. Este concepto nació en 2014. Las GAN proporcionan a las máquinas
                algo que podríamos llamar “imaginación” para crear cosas nuevas. Las redes neuronales buscan imitar al cerebro humano.
                Para ello, se enfrentan dos redes neuronales llamadas “generador” y “discriminador”. Ambas redes han sido entrenadas con los
                mismos datos y se van retroalimentando para ir mejorando y conseguir aprender a generar mejores imágenes.
                <br><br>En este  <a href="https://arxiv.org/pdf/1406.2661.pdf">informe </a> del 2014 se relata cómo a la hora de suministrar fotos de muchas personas
                a un ordenador, este era capaz de aprender cómo se forman los rasgos faciales de personas.
            </p>

            <p>
                Se han encontrado diversos casos de gente que se aprovecha de estas nuevas herramientas
                de diferentes maneras. La aparición de estafadores, bots y espías, que pueden usar las fotos
                para crear personajes falsos en línea, enmascarar el sesgo en la contratación y dañar
                los esfuerzos para llevar la diversidad a las industrias, también podría alimentar una
                mayor erosión de la confianza de la gente en los medios y en la tecnología, la cual se ve perjudicada
                por el mal uso que algunas personas pueden darle.
            </p>

            <br><br><h2><strong>Noticias encontradas</strong></h2>
            <p>
                Hemos encontrado noticias de sucesos que nos han enseñado la cantidad de posibilidades
                por las cuales se puede atacar a diversas personas y aprovecharse de ello.
                Vamos a enumerar unas cuantas junto a sus enlaces (algunas están en inglés):
            </p>

            <ul>
                <li>
                    Un <strong>deepfake</strong> (tecnología basada en Inteligencia Artificial utilizada con el fin de
                    crear contenido falso) crea imágenes falsas de mujeres desnudas a partir de una foto real
                    de ellas vestidas. Esto se podía conseguir de forma gratuita y automatizada, por ello se
                    estima que 105.000 mujeres fueron afectadas sin saberlo. Cogían las fotos de sus redes
                    sociales. Se encontraron también fotos de menores de edad. No funciona
                    con imágenes de hombres porque el software ha sido entrenado únicamente con fotos femeninas... Curioso, ¿verdad?.
                    Dejamos la reflexión del porqué de esto al lector.
                    <a href="https://www.infobae.com/america/tecno/2020/10/22/un-deepfake-ha-estado-desnudando-mujeres-y-ninas-sin-que-lo-sepan-en-telegram/">Saber más... </a><br><br>
                </li>
                <li>
                    Facebook elimina cuentas con fotos de perfil generadas por IA. Estas cuentas eran usadas
                    para difundir contenido político y hacer campañas. Para dar más autenticidad a estas cuentas
                    se generaron imágenes falsas para estos usuarios. La creación de cuentas falsas con propósito
                    político o de otra índole es algo más presente de lo que imaginamos.
                    <a href="https://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/">Saber más... </a><br><br>
                </li>
                <li>
                    Una noticia del mismo tipo que la anterior. A mediados del 2020, una campaña con propaganda a favor de China
                    estuvo criticando a los Estados Unidos por medio de una red de cuentas falsas con fotos
                    de perfil creadas con IA que se dedicaban a compartir y postear contenido intentando así conseguir un
                    mayor alcance para su mensaje.
                    <a href="https://www.pcmag.com/news/pro-china-propaganda-act-used-fake-followers-made-with-ai-generated-images">Saber más... </a><br><br>
                </li>
                <li>
                    Hay empresas que generan perfiles concretos de personas falsas para vender las imágenes, por
                    ejemplo, a redes de citas donde faltan mujeres y así llamar la atención de los usuarios masculinos
                    y obtener más beneficio.
                    <a href="https://www.washingtonpost.com/technology/2020/01/07/dating-apps-need-women-advertisers-need-diversity-ai-companies-offer-solution-fake-people/">Saber más... </a><br><br>
                </li>
                <li>
                    No solo existen las imágenes falsas, sino también los videos falsos. Ya es posible ver en videos como una persona diga y haga
                    cosas que realmente no estaba diciendo/haciendo. Esto sumado a las imágenes falsas y las fake news, hacen de la manipulación
                    y el engaño algo cada vez más difícil de detectar.
                    <a href="https://www.xataka.com/robotica-e-ia/deepfakes-tendremos-problema-verdad-videos-serviran-como-pruebas">Saber más... </a>
                </li>
            </ul>

            <br><br><h2><strong>¿Cómo detectar/prevenir imágenes de personas que no existen?</strong></h2>
            <p>
                La tarea es realmente difícil. La tecnología es muy buena y va evolucionando. Cada vez se irá perfeccionando
                más y hará más complicado diferenciar la realidad de lo creado por ella. Es posible que se llegue, en algún momento,
                al punto en el que sea imposible detectarlo.  Kyle McDonald cuenta en este <a href="https://kcimc.medium.com/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842">
                    post
                </a>, muchos trucos y ejemplos. Nosotros hemos recopilado algunos puntos en los que debes fijarte a la hora de
                identificar cuando en una imagen hay personas reales o no, sin olvidar la importancia del conocimiento que tenemos y la contrastación de la
                información. Debemos fijarnos en varios detalles:


            </p>

            <ol>
                <li>El <strong>pelo liso</strong>, que con frecuencia se ve poco natural.</li>
                <li>
                    La <strong>asimetría de las caras</strong>. Las orejas pueden estar en distintos niveles
                    o ser de tamaños y formas diferentes(en los <strong> pendientes</strong> y <strong>gafas</strong>
                    suelen ser visibles muchos defectos), el largo del pelo diferente, ropa con distinto aspecto, etc.
                </li>
                <li>Mechones de pelo excesivamente paralelos, o con apariencia extraña.</li>
                <li>
                    Los <strong>dientes</strong>, que pueden verse excesivamente anchos o estrechos o de aspecto difuso. Aún cuesta
                    generar detalles semirregulares.
                </li>
                <li>
                    Los <strong>fondos</strong>, son un buen lugar donde fijarse. Suelen ser muy difusos, deformados e incluso mostrar
                    elementos extraños.
                </li>
                <li>Los <strong>ojos</strong>, ya que pueden tener colores diferentes o apuntar a direcciones diferentes.</li>
                <li>Las <strong>manchas de agua</strong>, que aparecen a menudo en las imágenes generadas.</li>
            </ol>

            <br><div class="imgWrapper">
                <div class="pruebas">
                    <img src="./images/Pruebas/p1.jpg" />
                </div>
                <div class="pruebas">
                    <img src="./images/Pruebas/p2.jpg" />
                </div>
                <div class="pruebas">
                    <img src="./images/Pruebas/p3.jpg" />
                </div>
                <div class="pruebas">
                    <img src="./images/Pruebas/p4.jpg" />
                </div>
            </div>

            <br><p>
                En cambio, en las imágenes reales, los fondos son claros e incluso hay compañía humana real bien diferenciada, dientes claramente reales, pelo que no parece
                pintado o difuminado, simetría de pendientes y gafas... Con todos estos consejos, podemos llegar a diferenciar un poco
                mejor las imágenes.
            </p>


            <p>
                Los avances en el campo de la IA han llegado a generar imágenes, muy realistas y muy extrañas también, de personas, objetos, animales...
                Sin duda, es un tema que va a seguir dando mucho de que hablar.
                
            </p>

            <h3>Referencias</h3>
            <div id="referencias">
                <a href="https://www.infobae.com/america/tecno/2020/10/22/un-deepfake-ha-estado-desnudando-mujeres-y-ninas-sin-que-lo-sepan-en-telegram/">https://www.infobae.com/america/tecno/2020/10/22/un-deepfake-ha-estado-desnudando-mujeres-y-ninas-sin-que-lo-sepan-en-telegram/</a><br />
                <a href="https://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/">https://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/</a><br />
                <a href="https://www.pcmag.com/news/pro-china-propaganda-act-used-fake-followers-made-with-ai-generated-images">https://www.pcmag.com/news/pro-china-propaganda-act-used-fake-followers-made-with-ai-generated-images</a><br />
                <a href="https://www.theverge.com/2020/7/7/21315861/ai-generated-headshots-profile-pictures-fake-journalists-daily-beast-investigation">https://www.theverge.com/2020/7/7/21315861/ai-generated-headshots-profile-pictures-fake-journalists-daily-beast-investigation</a><br />
                <a href="https://www.washingtonpost.com/technology/2020/01/07/dating-apps-need-women-advertisers-need-diversity-ai-companies-offer-solution-fake-people/">https://www.washingtonpost.com/technology/2020/01/07/dating-apps-need-women-advertisers-need-diversity-ai-companies-offer-solution-fake-people/</a><br />
                <a href="https://www.theverge.com/2018/12/17/18144356/ai-image-generation-fake-faces-people-nvidia-generative-adversarial-networks-gans">https://www.theverge.com/2018/12/17/18144356/ai-image-generation-fake-faces-people-nvidia-generative-adversarial-networks-gans</a><br />

                <!--  <a href="https://www.xataka.com/robotica-e-ia/deepfakes-tendremos-problema-verdad-videos-serviran-como-prueba">https://www.xataka.com/robotica-e-ia/deepfakes-tendremos-problema-verdad-videos-serviran-como-prueba</a><br /> -->
                <a href="https://www.xataka.com/robotica-e-ia/asi-puedes-superar-test-para-detectar-que-fotos-celebrities-han-sido-creadas-mediante-inteligencia-artificial">https://www.xataka.com/robotica-e-ia/asi-puedes-superar-test-para-detectar-que-fotos-celebrities-han-sido-creadas-mediante-inteligencia-artificial</a><br />
            </div>

        </div>

    </div>

    <footer class="pie">
        <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">
            <img id="creative" alt="Licencia Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" />
        </a>
        <br />Esta obra está bajo una <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">Licencia Creative Commons Atribución-NoComercial-SinDerivadas 4.0 Internacional</a>
    </footer>
</body>
</html>